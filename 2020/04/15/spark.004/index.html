<!DOCTYPE html>
<html lang="zh-Hansn">





<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/avatar.png">
  <link rel="icon" type="image/png" href="/img/avatar.png">
  <meta name="viewport"
        content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="description" content="">
  <meta name="author" content="JiaoPan">
  <meta name="keywords" content="deep learning|computer vision">
  <title>004.Spark Machine Learning ~ 今天的风儿甚是喧嚣 JiaoPan</title>

  <link rel="stylesheet" href="/lib/font-awesome/css/all.min.css"  >
<link rel="stylesheet" href="/lib/bootstrap/css/bootstrap.min.css"  >
<link rel="stylesheet" href="/lib/mdbootstrap/css/mdb.min.css"  >
<link rel="stylesheet" href="/lib/github-markdown/github-markdown.min.css"  >

<link rel="stylesheet" href="//at.alicdn.com/t/font_1067060_qzomjdt8bmp.css">



  <link rel="stylesheet" href="/lib/prettify/tomorrow-night-eighties.min.css"  >

<link rel="stylesheet" href="/css/main.css"  >


  <link rel="stylesheet" href="/lib/fancybox/jquery.fancybox.min.css"  >


<meta name="generator" content="Hexo 4.2.0"></head>


<body>
  <header style="height: 70vh;">
    <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand"
       href="/">&nbsp;<strong>今天的风儿甚是喧嚣 JiaoPan</strong>&nbsp;</a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
          <li class="nav-item">
            <a class="nav-link" href="/">主页</a>
          </li>
        
          
          
          
          
          <li class="nav-item">
            <a class="nav-link" href="/archives/">归档</a>
          </li>
        
          
          
          
          
          <li class="nav-item">
            <a class="nav-link" href="/categories/">分类</a>
          </li>
        
          
          
          
          
          <li class="nav-item">
            <a class="nav-link" href="/tags/">标签</a>
          </li>
        
          
          
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" data-toggle="modal" data-target="#modalSearch">&nbsp;&nbsp;<i
                class="iconfont icon-search"></i>&nbsp;&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

    <div class="view intro-2" id="background"
         style="background: url('/img/default.png')no-repeat center center;
           background-size: cover;
           background-attachment: fixed;">
      <div class="full-bg-img">
        <div class="mask rgba-black-light flex-center">
          <div class="container text-center white-text fadeInUp">
            <span class="h2" id="subtitle">
              
            </span>

            
              <br>
              
                <p class="mt-3">
                  <i class="fas fa-calendar-alt" aria-hidden="true"></i>&nbsp;
                  Wednesday, April 15th 2020, 4:14 pm
                </p>
              

              <p>
                
                  
                  &nbsp;<i class="far fa-chart-bar"></i>
                  <span class="post-count">
                    2.1k 字
                  </span>&nbsp;
                

                
                  
                  &nbsp;<i class="far fa-clock"></i>
                  <span class="post-count">
                      12 分钟
                  </span>&nbsp;
                

                
                  <!-- 不蒜子统计文章PV -->
                  
                  &nbsp;<i class="far fa-eye" aria-hidden="true"></i>&nbsp;
                  <span id="busuanzi_container_page_pv">
                    <span id="busuanzi_value_page_pv"></span> 次
                  </span>&nbsp;
                
              </p>
            
          </div>

          
        </div>
      </div>
    </div>
  </header>

  <main>
    
      

<div class="container-fluid">
  <div class="row">
    <div class="d-none d-lg-block col-lg-2"></div>
    <div class="col-lg-8 nopadding-md">
      <div class="py-5 z-depth-3" id="board">
        <div class="post-content mx-auto" id="post">
          <div class="markdown-body">
            <h1 id="Spark-Machine-Learning"><a href="#Spark-Machine-Learning" class="headerlink" title="Spark Machine Learning"></a>Spark Machine Learning</h1><ul>
<li>引入依赖</li>
</ul>
<pre><code class="lang-text">&lt;dependency&gt;
  &lt;groupId&gt;org.apache.spark&lt;/groupId&gt;
  &lt;artifactId&gt;spark-mllib_2.11&lt;/artifactId&gt;
  &lt;version&gt;2.4.5&lt;/version&gt;
&lt;/dependency&gt;
</code></pre>
<h1 id="相关系数矩阵"><a href="#相关系数矩阵" class="headerlink" title="相关系数矩阵"></a>相关系数矩阵</h1><p>相关系数矩阵(i行，j列)的元素是原矩阵i列与j列的相关系数</p>
<pre><code class="lang-java">#身高与体重的相关系数矩阵
SparkSession spark = SparkSession.builder().appName(&quot;ml test&quot;)
                 .master(&quot;local[*]&quot;)
                 .getOrCreate();
List&lt;Row&gt; data = Arrays.asList(
          RowFactory.create(Vectors.dense(172, 60)),
          RowFactory.create(Vectors.dense(175, 65)),
          RowFactory.create(Vectors.dense(180, 70)),
          RowFactory.create(Vectors.dense(190, 80))
);

StructType schema = new StructType(new StructField[]{
  new StructField(&quot;features&quot;, new VectorUDT(), false, Metadata.empty()),
});

Dataset&lt;Row&gt; df = spark.createDataFrame(data, schema);
df.show();
Row pearson = Correlation.corr(df, &quot;features&quot;).head();
System.out.println(&quot;Pearson correlation matrix:\n&quot; + pearson);

Row spearman = Correlation.corr(df, &quot;features&quot;, &quot;spearman&quot;).head();
System.out.println(&quot;Spearman correlation matrix:\n&quot; + spearman);

+------------+
|    features|
+------------+
|[172.0,60.0]|
|[175.0,65.0]|
|[180.0,70.0]|
|[190.0,80.0]|
+------------+

Pearson correlation matrix:
[1.0                 0.9957069831288888  
0.9957069831288888  1.0                 ]

Spearman correlation matrix:
[1.0                 0.9999999999999981  
0.9999999999999981  1.0                 ]
</code></pre>
<h1 id="Extracting-transforming-and-selecting-features"><a href="#Extracting-transforming-and-selecting-features" class="headerlink" title="Extracting, transforming and selecting features"></a>Extracting, transforming and selecting features</h1><h2 id="Tokenizer-分词"><a href="#Tokenizer-分词" class="headerlink" title="Tokenizer 分词"></a>Tokenizer 分词</h2><pre><code class="lang-java">SparkSession spark = SparkSession.builder().appName(&quot;ml test&quot;)
                 .master(&quot;local[*]&quot;)
                 .getOrCreate();
List&lt;Row&gt; data = Arrays.asList(
                RowFactory.create(0, &quot;Hi I heard about Spark&quot;),
                RowFactory.create(1, &quot;I wish Java could use case classes&quot;),
                RowFactory.create(2, &quot;Logistic,regression,models,are,neat&quot;)
        );

StructType schema = new StructType(new StructField[]{
        new StructField(&quot;id&quot;, DataTypes.IntegerType, false, Metadata.empty()),
        new StructField(&quot;sentence&quot;, DataTypes.StringType, false, Metadata.empty())
});

Dataset&lt;Row&gt; sentenceDataFrame = spark.createDataFrame(data, schema);

Tokenizer tokenizer = new Tokenizer().setInputCol(&quot;sentence&quot;).setOutputCol(&quot;words&quot;);
Dataset&lt;Row&gt; tokenized = tokenizer.transform(sentenceDataFrame);
tokenized.show(false);

//正则
RegexTokenizer regexTokenizer = new RegexTokenizer()
        .setInputCol(&quot;sentence&quot;)
        .setOutputCol(&quot;words&quot;)
        .setPattern(&quot;\\W&quot;);  // alternatively .setPattern(&quot;\\w+&quot;).setGaps(false);
Dataset&lt;Row&gt; regexTokenized = regexTokenizer.transform(sentenceDataFrame);
regexTokenized.show(false);

+---+-----------------------------------+------------------------------------------+
|id |sentence                           |words                                     |
+---+-----------------------------------+------------------------------------------+
|0  |Hi I heard about Spark             |[hi, i, heard, about, spark]              |
|1  |I wish Java could use case classes |[i, wish, java, could, use, case, classes]|
|2  |Logistic,regression,models,are,neat|[logistic,regression,models,are,neat]     |
+---+-----------------------------------+------------------------------------------+

+---+-----------------------------------+------------------------------------------+
|id |sentence                           |words                                     |
+---+-----------------------------------+------------------------------------------+
|0  |Hi I heard about Spark             |[hi, i, heard, about, spark]              |
|1  |I wish Java could use case classes |[i, wish, java, could, use, case, classes]|
|2  |Logistic,regression,models,are,neat|[logistic, regression, models, are, neat] |
+---+-----------------------------------+------------------------------------------+
</code></pre>
<h2 id="StopWordsRemover-停止词"><a href="#StopWordsRemover-停止词" class="headerlink" title="StopWordsRemover 停止词"></a>StopWordsRemover 停止词</h2><pre><code class="lang-java">SparkSession spark = SparkSession.builder().appName(&quot;ml test&quot;)
                 .master(&quot;local[*]&quot;)
                 .getOrCreate();
StopWordsRemover remover = new StopWordsRemover()
                .setInputCol(&quot;raw&quot;)
                .setOutputCol(&quot;filtered&quot;);

List&lt;Row&gt; data = Arrays.asList(
        RowFactory.create(Arrays.asList(&quot;I&quot;, &quot;saw&quot;, &quot;the&quot;, &quot;red&quot;, &quot;balloon&quot;)),
        RowFactory.create(Arrays.asList(&quot;Mary&quot;, &quot;had&quot;, &quot;a&quot;, &quot;little&quot;, &quot;lamb&quot;))
);

StructType schema = new StructType(new StructField[]{
        new StructField(&quot;raw&quot;, DataTypes.createArrayType(DataTypes.StringType), false, Metadata.empty())
});

Dataset&lt;Row&gt; dataset = spark.createDataFrame(data, schema);
remover.transform(dataset).show(false);

+----------------------------+--------------------+
|raw                         |filtered            |
+----------------------------+--------------------+
|[I, saw, the, red, balloon] |[saw, red, balloon] |
|[Mary, had, a, little, lamb]|[Mary, little, lamb]|
+----------------------------+--------------------+
</code></pre>
<h2 id="n-gram"><a href="#n-gram" class="headerlink" title="$n$  -gram"></a>$n$  -gram</h2><pre><code class="lang-java">SparkSession spark = SparkSession.builder().appName(&quot;ml test&quot;)
                 .master(&quot;local[*]&quot;)
                 .getOrCreate();

List&lt;Row&gt; data = Arrays.asList(
        RowFactory.create(0, Arrays.asList(&quot;Hi&quot;, &quot;I&quot;, &quot;heard&quot;, &quot;about&quot;, &quot;Spark&quot;)),
        RowFactory.create(1, Arrays.asList(&quot;I&quot;, &quot;wish&quot;, &quot;Java&quot;, &quot;could&quot;, &quot;use&quot;, &quot;case&quot;, &quot;classes&quot;)),
        RowFactory.create(2, Arrays.asList(&quot;Logistic&quot;, &quot;regression&quot;, &quot;models&quot;, &quot;are&quot;, &quot;neat&quot;))
);

StructType schema = new StructType(new StructField[]{
        new StructField(&quot;id&quot;, DataTypes.IntegerType, false, Metadata.empty()),
        new StructField(
                &quot;words&quot;, DataTypes.createArrayType(DataTypes.StringType), false, Metadata.empty())
});

Dataset&lt;Row&gt; wordDataFrame = spark.createDataFrame(data, schema);

NGram ngramTransformer = new NGram().setN(2).setInputCol(&quot;words&quot;).setOutputCol(&quot;ngrams&quot;);

Dataset&lt;Row&gt; ngramDataFrame = ngramTransformer.transform(wordDataFrame);
ngramDataFrame.select(&quot;ngrams&quot;).show(false);
</code></pre>
<h2 id="Binarization-二值化"><a href="#Binarization-二值化" class="headerlink" title="Binarization 二值化"></a>Binarization 二值化</h2><pre><code class="lang-java">SparkSession spark = SparkSession.builder().appName(&quot;ml test&quot;)
                 .master(&quot;local[*]&quot;)
                 .getOrCreate();
List&lt;Row&gt; data = Arrays.asList(
        RowFactory.create(0, 0.1),
        RowFactory.create(1, 0.8),
        RowFactory.create(2, 0.2)
);
StructType schema = new StructType(new StructField[]{
        new StructField(&quot;id&quot;, DataTypes.IntegerType, false, Metadata.empty()),
        new StructField(&quot;feature&quot;, DataTypes.DoubleType, false, Metadata.empty())
});
Dataset&lt;Row&gt; continuousDataFrame = spark.createDataFrame(data, schema);

Binarizer binarizer = new Binarizer()
        .setInputCol(&quot;feature&quot;)
        .setOutputCol(&quot;binarized_feature&quot;)
        .setThreshold(0.5);

Dataset&lt;Row&gt; binarizedDataFrame = binarizer.transform(continuousDataFrame);

System.out.println(&quot;Binarizer output with Threshold = &quot; + binarizer.getThreshold());
binarizedDataFrame.show();

+---+-------+-----------------+
| id|feature|binarized_feature|
+---+-------+-----------------+
|  0|    0.1|              0.0|
|  1|    0.8|              1.0|
|  2|    0.2|              0.0|
+---+-------+-----------------+
</code></pre>
<h2 id="PCA-主成成分分析"><a href="#PCA-主成成分分析" class="headerlink" title="PCA 主成成分分析"></a>PCA 主成成分分析</h2><pre><code>SparkSession spark = SparkSession.builder().appName(&quot;ml test&quot;)
                 .master(&quot;local[*]&quot;)
                 .getOrCreate();
List&lt;Row&gt; data = Arrays.asList(
        RowFactory.create(Vectors.sparse(5, new int[]{1, 3}, new double[]{1.0, 7.0})),
        RowFactory.create(Vectors.dense(2.0, 0.0, 3.0, 4.0, 5.0)),
        RowFactory.create(Vectors.dense(4.0, 0.0, 0.0, 6.0, 7.0))
);

StructType schema = new StructType(new StructField[]{
        new StructField(&quot;features&quot;, new VectorUDT(), false, Metadata.empty()),
});

Dataset&lt;Row&gt; df = spark.createDataFrame(data, schema);

PCAModel pca = new PCA()
        .setInputCol(&quot;features&quot;)
        .setOutputCol(&quot;pcaFeatures&quot;)
        .setK(3)
        .fit(df);

Dataset&lt;Row&gt; result = pca.transform(df).select(&quot;pcaFeatures&quot;);
result.show(false);

+-----------------------------------------------------------+
|pcaFeatures                                                |
+-----------------------------------------------------------+
|[1.6485728230883807,-4.013282700516296,-5.524543751369388] |
|[-4.645104331781534,-1.1167972663619026,-5.524543751369387]|
|[-6.428880535676489,-5.337951427775355,-5.524543751369389] |
+-----------------------------------------------------------+
</code></pre><h2 id="PolynomialExpansion-多项式转化"><a href="#PolynomialExpansion-多项式转化" class="headerlink" title="PolynomialExpansion 多项式转化"></a>PolynomialExpansion 多项式转化</h2><pre><code class="lang-java">PolynomialExpansion polyExpansion = new PolynomialExpansion()
                .setInputCol(&quot;features&quot;)
                .setOutputCol(&quot;polyFeatures&quot;)
                .setDegree(2);

List&lt;Row&gt; data = Arrays.asList(
        RowFactory.create(Vectors.dense(2.0, 1.0)),
        RowFactory.create(Vectors.dense(0.0, 0.0)),
        RowFactory.create(Vectors.dense(3.0, -1.0))
);
StructType schema = new StructType(new StructField[]{
        new StructField(&quot;features&quot;, new VectorUDT(), false, Metadata.empty()),
});
Dataset&lt;Row&gt; df = spark.createDataFrame(data, schema);

Dataset&lt;Row&gt; polyDF = polyExpansion.transform(df);
polyDF.show(false);

+----------+-----------------------+
|features  |polyFeatures           |
+----------+-----------------------+
|[2.0,1.0] |[2.0,4.0,1.0,2.0,1.0]  |
|[0.0,0.0] |[0.0,0.0,0.0,0.0,0.0]  |
|[3.0,-1.0]|[3.0,9.0,-1.0,-3.0,1.0]|
+----------+-----------------------+
</code></pre>
<h2 id="TF-IDF"><a href="#TF-IDF" class="headerlink" title="TF-IDF"></a>TF-IDF</h2><ul>
<li>TF:词频，词条在<strong>给定文档</strong>中所出现的频率,值越大则词条在该文档中重要性越大</li>
</ul>
<p>词条 $i$ 的TF： $TF_i$ = $\frac{N_i}{N}$  ( $N$ ：给定文档的总词条数)</p>
<ul>
<li>IDF：逆向文本频率，词条在<strong>所有文档</strong>中出现的频率，值越大则词条在该文档中重要性越小</li>
</ul>
<p>词条 $i$ 的IDF： $IDF_i$ = $log(\frac{D}{D_i+1})$  ( $D$ :总文档数， $D_i$ :包含词条 $i$ 的文档数)</p>
<p>TF-IDF $_i$ = $TF_i*IDF_i$  (词条 $i$ 的TF-IDF值)</p>
<pre><code class="lang-java">SparkSession spark = SparkSession.builder().appName(&quot;ml test&quot;)
                 .master(&quot;local[*]&quot;)
                 .getOrCreate();
List&lt;Row&gt; data = Arrays.asList(
                  RowFactory.create(0.0, &quot;I love spark spark spark&quot;),
                  RowFactory.create(1.0, &quot;I love java java is my life&quot;),
                  RowFactory.create(2.0, &quot;I love C++ C++ is the best&quot;)
        );

StructType schema = new StructType(new StructField[]{
          new StructField(&quot;label&quot;, DataTypes.DoubleType, false, Metadata.empty()),
          new StructField(&quot;sentence&quot;, DataTypes.StringType, false, Metadata.empty())
});
Dataset&lt;Row&gt; sentenceData = spark.createDataFrame(data, schema);
sentenceData.show();

Tokenizer tokenizer = new Tokenizer().setInputCol(&quot;sentence&quot;).setOutputCol(&quot;words&quot;); //分词
Dataset&lt;Row&gt; wordsData = tokenizer.transform(sentenceData);
wordsData.show();

int numFeatures = 20;
HashingTF hashingTF = new HashingTF().setInputCol(&quot;words&quot;).setOutputCol(&quot;rawFeatures&quot;).setNumFeatures(numFeatures);
Dataset&lt;Row&gt; featurizedData = hashingTF.transform(wordsData);
featurizedData.show();

IDF idf = new IDF().setInputCol(&quot;rawFeatures&quot;).setOutputCol(&quot;features&quot;);
IDFModel idfModel = idf.fit(featurizedData);


Dataset&lt;Row&gt; rescaledData = idfModel.transform(featurizedData);
rescaledData.show();


+-----+--------------------+
|label|            sentence|
+-----+--------------------+
|  0.0|I love spark spar...|
|  1.0|I love java java ...|
|  2.0|I love C++ C++ is...|
+-----+--------------------+

+-----+--------------------+--------------------+
|label|            sentence|               words|
+-----+--------------------+--------------------+
|  0.0|I love spark spar...|[i, love, spark, ...|
|  1.0|I love java java ...|[i, love, java, j...|
|  2.0|I love C++ C++ is...|[i, love, c++, c+...|

#rawFeatures:hash桶数、词hash索引、词频率
+-----+--------------------+--------------------+--------------------+
|label|            sentence|               words|         rawFeatures|
+-----+--------------------+--------------------+--------------------+
|  0.0|I love spark spar...|[i, love, spark, ...|(20,[0,5,9],[1.0,...|
|  1.0|I love java java ...|[i, love, java, j...|(20,[0,1,7,9,16,1...|
|  2.0|I love C++ C++ is...|[i, love, c++, c+...|(20,[0,1,3,9,10,1...|
+-----+--------------------+--------------------+--------------------+

+-----+--------------------+--------------------+--------------------+--------------------+
|label|            sentence|               words|         rawFeatures|            features|
+-----+--------------------+--------------------+--------------------+--------------------+
|  0.0|I love spark spar...|[i, love, spark, ...|(20,[0,5,9],[1.0,...|(20,[0,5,9],[0.0,...|
|  1.0|I love java java ...|[i, love, java, j...|(20,[0,1,7,9,16,1...|(20,[0,1,7,9,16,1...|
|  2.0|I love C++ C++ is...|[i, love, c++, c+...|(20,[0,1,3,9,10,1...|(20,[0,1,3,9,10,1...|
+-----+--------------------+--------------------+--------------------+--------------------+
</code></pre>
<h2 id="CountVectorizer"><a href="#CountVectorizer" class="headerlink" title="CountVectorizer"></a>CountVectorizer</h2><pre><code class="lang-java">SparkSession spark = SparkSession.builder().appName(&quot;ml test&quot;)
                 .master(&quot;local[*]&quot;)
                 .getOrCreate();
List&lt;Row&gt; data = Arrays.asList(
                  RowFactory.create(&quot;I love spark spark spark&quot;),
                  RowFactory.create(&quot;I love java java is my life&quot;),
                  RowFactory.create(&quot;I love C++ C++ is the best&quot;)
        );
StructType schema = new StructType(new StructField[]{
          new StructField(&quot;sentence&quot;, DataTypes.StringType, false, Metadata.empty())
});
Dataset&lt;Row&gt; sentenceData = spark.createDataFrame(data, schema);
sentenceData.show();

Tokenizer tokenizer = new Tokenizer().setInputCol(&quot;sentence&quot;).setOutputCol(&quot;words&quot;); //分词
Dataset&lt;Row&gt; wordsData = tokenizer.transform(sentenceData);
wordsData.show();

CountVectorizerModel cvModel = new CountVectorizer()
                              .setInputCol(&quot;words&quot;)
                              .setOutputCol(&quot;feature&quot;)
                              //.setVocabSize(3)
                              //.setMinDF(2)
                              .fit(wordsData);
System.out.println(Arrays.asList(cvModel.vocabulary()));
cvModel.transform(wordsData).show(false);

+--------------------+
|            sentence|
+--------------------+
|I love spark spar...|
|I love java java ...|
|I love C++ C++ is...|
+--------------------+
+--------------------+--------------------+
|            sentence|               words|
+--------------------+--------------------+
|I love spark spar...|[i, love, spark, ...|
|I love java java ...|[i, love, java, j...|
|I love C++ C++ is...|[i, love, c++, c+...|
+--------------------+--------------------+

[love, spark, i, c++, java, is, the, life, best, my]

#feature:词总数、词索引、词频率
+---------------------------+-----------------------------------+--------------------------------------------+
|sentence                   |words                              |feature                                     |
+---------------------------+-----------------------------------+--------------------------------------------+
|I love spark spark spark   |[i, love, spark, spark, spark]     |(10,[0,1,2],[1.0,3.0,1.0])                  |
|I love java java is my life|[i, love, java, java, is, my, life]|(10,[0,2,4,5,7,9],[1.0,1.0,2.0,1.0,1.0,1.0])|
|I love C++ C++ is the best |[i, love, c++, c++, is, the, best] |(10,[0,2,3,5,6,8],[1.0,1.0,2.0,1.0,1.0,1.0])|
+---------------------------+-----------------------------------+--------------------------------------------+
</code></pre>
<h2 id="FeatureHasher"><a href="#FeatureHasher" class="headerlink" title="FeatureHasher"></a>FeatureHasher</h2><pre><code class="lang-java">SparkSession spark = SparkSession.builder().appName(&quot;ml test&quot;)
                 .master(&quot;local[*]&quot;)
                 .getOrCreate();
List&lt;Row&gt; data = Arrays.asList(
                RowFactory.create(2.2, true, &quot;1&quot;, &quot;foo&quot;),
                RowFactory.create(3.3, false, &quot;2&quot;, &quot;bar&quot;),
                RowFactory.create(4.4, false, &quot;3&quot;, &quot;baz&quot;),
                RowFactory.create(5.5, false, &quot;4&quot;, &quot;foo&quot;)
        );
StructType schema = new StructType(new StructField[]{
        new StructField(&quot;real&quot;, DataTypes.DoubleType, false, Metadata.empty()),
        new StructField(&quot;bool&quot;, DataTypes.BooleanType, false, Metadata.empty()),
        new StructField(&quot;stringNum&quot;, DataTypes.StringType, false, Metadata.empty()),
        new StructField(&quot;string&quot;, DataTypes.StringType, false, Metadata.empty())
});
Dataset&lt;Row&gt; dataset = spark.createDataFrame(data, schema);
FeatureHasher hasher = new FeatureHasher()
        .setInputCols(new String[]{&quot;real&quot;, &quot;bool&quot;, &quot;stringNum&quot;, &quot;string&quot;})
        .setOutputCol(&quot;features&quot;);

Dataset&lt;Row&gt; featurized = hasher.transform(dataset);

featurized.show(false);

+----+-----+---------+-------------------+
|real|bool |stringNum|features           |
+----+-----+---------+-------------------+
|2.2 |true |1        |(2,[0,1],[2.0,2.2])|
|3.3 |false|2        |(2,[0,1],[1.0,4.3])|
|4.4 |false|3        |(2,[0,1],[2.0,4.4])|
|5.5 |false|4        |(2,[0,1],[1.0,6.5])|
+----+-----+---------+-------------------+
</code></pre>

            <hr>
          </div>
          <br>
          <div>
            <p>
            
              <span>
                <i class="iconfont icon-inbox"></i>
                
                  <a class="hover-with-bg" href="/categories/spark">spark</a>
                  &nbsp;
                
              </span>&nbsp;&nbsp;
            
            
            </p>
            
              <p class="note note-warning">本博客所有文章除特别声明外，均采用 <a href="https://zh.wikipedia.org/wiki/Wikipedia:CC_BY-SA_3.0%E5%8D%8F%E8%AE%AE%E6%96%87%E6%9C%AC" target="_blank" rel="nofollow noopener noopener">CC BY-SA 3.0协议</a> 。转载请注明出处！</p>
            
          </div>
        </div>
      </div>
    </div>
    <div class="d-none d-lg-block col-lg-2 toc-container">
      
  <div id="toc">
    <p class="h4"><i class="far fa-list-alt"></i>&nbsp;TOC</p>
    <div id="tocbot"></div>
  </div>

    </div>
  </div>
</div>

<!-- custom -->


<!-- Comments -->
<div class="col-lg-7 mx-auto nopadding-md">
  <div class="container comments mx-auto" id="comments">
    
      <br><br>
      
      
  <script defer src="https://utteranc.es/client.js"
          repo="JiaoPaner/blog-talk"
          issue-term="pathname"
  
          label="utterances"
    
          theme="github-light"
          crossorigin="anonymous"
          async>
  </script>


    
  </div>
</div>

    
  </main>

  
    <a class="z-depth-1" id="scroll-top-button" href="#" role="button">
      <i class="fa fa-chevron-up scroll-top-arrow" aria-hidden="true"></i>
    </a>
  

  
    <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">Search</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v"
                 for="local-search-input">keyword</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>
  

  <footer class="mt-5">
  <div class="text-center py-3">
    <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><b>Hexo</b></a>
    <i class="iconfont icon-love"></i>
    <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"> <b>Fluid</b></a>
    <br>

    
  
    <!-- 不蒜子统计PV -->
    
    &nbsp;<span id="busuanzi_container_site_pv">总访问量 
          <span id="busuanzi_value_site_pv"></span> 次</span>&nbsp;
  
  
    <!-- 不蒜子统计UV -->
    
    &nbsp;<span id="busuanzi_container_site_uv">总访客数 
            <span id="busuanzi_value_site_uv"></span> 人</span>&nbsp;
  
  <br>



    


    <!-- cnzz Analytics icon -->
    

  </div>
</footer>

<!-- SCRIPTS -->
<script src="/lib/jquery/jquery.min.js" ></script>
<script src="/lib/popper/popper.min.js" ></script>
<script src="/lib/bootstrap/js/bootstrap.min.js" ></script>
<script src="/lib/mdbootstrap/js/mdb.min.js" ></script>
<script src="/js/main.js" ></script>


  <script src="/js/lazyload.js" ></script>



  
    <script src="/lib/tocbot/tocbot.min.js" ></script>
  
  <script src="/js/post.js" ></script>



  <script src="/lib/smooth-scroll/smooth-scroll.min.js" ></script>



  <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" ></script>


<!-- Plugins -->


  

  

  

  

  <!-- cnzz Analytics -->
  



  <script src="/lib/prettify/prettify.min.js" ></script>
  <script>
    $(document).ready(function () {
      $('pre').addClass('prettyprint  linenums');
      prettyPrint();
    })
  </script>



  <script src="/lib/typed/typed.min.js" ></script>
  <script>
    var typed = new Typed('#subtitle', {
      strings: [
        '  ',
        "004.Spark Machine Learning&nbsp;",
      ],
      cursorChar: ".",
      typeSpeed: 70,
      loop: false,
    });
    typed.stop();
    $(document).ready(function () {
      $(".typed-cursor").addClass("h2");
      typed.start();
    });
  </script>



  <script src="/lib/anchor/anchor.min.js" ></script>
  <script>
    anchors.options = {
      placement: "right",
      visible: "false",
      
    };
    var el = "h1,h2,h3,h4,h5,h6".split(",");
    var res = [];
    for (item of el) {
      res.push(".markdown-body > " + item)
    }
    anchors.add(res.join(", "))
  </script>



  <script src="/js/local-search.js" ></script>
  <script>
    var path = "/local-search.xml";
    var inputArea = document.querySelector("#local-search-input");
    inputArea.onclick = function () {
      getSearchFile(path);
      this.onclick = null
    }
  </script>



  <script src="/lib/fancybox/jquery.fancybox.min.js" ></script>
  <script>
    $("#post img:not(.no-zoom img, img[no-zoom])").each(
      function () {
        var element = document.createElement("a");
        $(element).attr("data-fancybox", "images");
        $(element).attr("href", $(this).attr("src"));
        $(this).wrap(element);
      }
    );
  </script>



  

  
    <!-- MathJax -->
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
          tex2jax: {
              inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
              processEscapes: true,
              skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
          }
      });

      MathJax.Hub.Queue(function() {
          var all = MathJax.Hub.getAllJax(), i;
          for(i=0; i < all.length; i += 1) {
              all[i].SourceElement().parentNode.className += ' has-jax';
          }
      });

    </script>

    <script src="https://cdn.staticfile.org/mathjax/2.7.6/MathJax.js?config=TeX-MML-AM_CHTML" ></script>

  









</body>
</html>
